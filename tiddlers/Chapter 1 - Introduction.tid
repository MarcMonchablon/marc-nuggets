created: 20141105191545612
modified: 20141105193035310
tags: [[Seven Concurrency Models in Seven Weeks]]
title: Chapter 1 - Introduction
type: text/vnd.tiddlywiki

Even tought they are often used interchangeably, //concurrent// and //parallel// refer to related but different things !

* A //concurrent// program has multiple logical //threads of control//. Theses threads may or may not run in parallel. __Concurrency is an aspect of the //problem// domain__
* A //parallel// program potentially run more quickly than a sequential program. It may or may not have more than one logical thread of control. __Parallelism is an aspect of the //solution// domain__

<<<
Concurrency is about dealing with lots of things at once.

Parallelism is about doing lots of things at once.
<<< Rob Pike

Concurrency and parallelism is often confused because traditional threads end locks don't provide any direct support for parallelism. If you want to exploit multiple cores with threads and lokcs, your only choice is to create a concurrent program and then run on parallel hardware.

It is unfortunate because concurrent program are often __nondeterministic__ (do different things depending on precise timing of events). Nondeterminism is natural and to be expected if we are dealing with a genuinely concurrent problem !

However, parallelism doesn't have to be necessary nondeterministic. Language with explicit support for paralellism allow you to write parallel code without introducting the specter of nondeterminism.

---

From a programmer's point of view, the most important distinguishing feature of a multiprocessor architecture is the memory model, specifically whether it's //shared// or //distributed//.

* In a //shared-memory processor//, each processor can accessn any memory location. Interprocessor communication is primarily through memory.

* In a //distributed-memory processor//, each processor has is own local memory. Interprocessor communication is primarily via the network.